{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c09bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456428e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a29447e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
       "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
       "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
       "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
       "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
       "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
       "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
       "2  Apesar de larga vitória nas legislativas, Macr...   \n",
       "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
       "4  Após queda em maio, a atividade econômica sobe...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
       "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
       "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
       "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
       "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
       "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino = pd.read_csv(\"data/treino.csv\")\n",
    "dados_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7abc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Rio de !!!janeiro$$$$$ é uma cidade maravilhosa\"\n",
    "doc = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ea52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b8529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_textos(doc):\n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text)\n",
    "        \n",
    "    if len(tokens_validos) > 2:\n",
    "        return \" \".join(tokens_validos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6e6135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rio cidade maravilhosa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trata_textos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c2feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.688579992453257\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# pegar o início da execução (para calcular o tempo levado para o processamento)\n",
    "t0 = time()\n",
    "\n",
    "# processar em paralelo e enviar em lotes\n",
    "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
    "                                                       batch_size = 1000,\n",
    "                                                       n_process = -1)]\n",
    "\n",
    "tf = time() - t0\n",
    "\n",
    "print(tf/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c023d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queda maio atividade econômica sobe junho bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo\n",
       "0  polêmica marine le pen abomina negacionistas h...\n",
       "1  macron le pen turno frança revés siglas tradic...\n",
       "2  apesar larga vitória legislativas macron terá ...\n",
       "3  governo antecipa balanço alckmin anuncia queda...\n",
       "4       queda maio atividade econômica sobe junho bc"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_tratados = pd.DataFrame({\"titulo\":textos_tratados})\n",
    "\n",
    "titulos_tratados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2639af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0,\n",
    "                     window = 2,\n",
    "                     #size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c89fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fe81032ef50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3546e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "84466\n"
     ]
    }
   ],
   "source": [
    "print(len(titulos_tratados))\n",
    "\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
    "\n",
    "print(len(titulos_tratados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51684a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d948142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:16:27,319 : - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=100, alpha=0.03)', 'datetime': '2021-09-15T18:16:27.319522', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'created'}\n",
      "2021-09-15 18:16:27,323 : - collecting all words and their counts\n",
      "2021-09-15 18:16:27,325 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-15 18:16:27,347 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2021-09-15 18:16:27,364 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2021-09-15 18:16:27,386 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2021-09-15 18:16:27,408 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2021-09-15 18:16:27,423 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2021-09-15 18:16:27,442 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2021-09-15 18:16:27,462 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2021-09-15 18:16:27,479 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2021-09-15 18:16:27,504 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2021-09-15 18:16:27,523 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2021-09-15 18:16:27,539 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2021-09-15 18:16:27,560 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2021-09-15 18:16:27,581 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2021-09-15 18:16:27,593 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2021-09-15 18:16:27,605 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2021-09-15 18:16:27,625 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2021-09-15 18:16:27,644 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2021-09-15 18:16:27,645 : - Creating a fresh vocabulary\n",
      "2021-09-15 18:16:27,748 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.559897211095155%% of original 39693, drops 26769)', 'datetime': '2021-09-15T18:16:27.748432', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-15 18:16:27,749 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.66688261927062%% of original 540242, drops 45019)', 'datetime': '2021-09-15T18:16:27.749617', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-15 18:16:27,871 : - deleting the raw counts dictionary of 39693 items\n",
      "2021-09-15 18:16:27,890 : - sample=0.001 downsamples 8 most-common words\n",
      "2021-09-15 18:16:27,890 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2021-09-15T18:16:27.890763', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-15 18:16:28,097 : - estimated required memory for 12924 words and 100 dimensions: 16801200 bytes\n",
      "2021-09-15 18:16:28,099 : - resetting layer weights\n",
      "2021-09-15 18:16:28,117 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-15T18:16:28.117454', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0,\n",
    "                     window = 2,\n",
    "                     #size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)\n",
    "\n",
    "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e8f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:18:32,234 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2021-09-15T18:18:32.234646', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n",
      "2021-09-15 18:18:32,824 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:32,846 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:32,847 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:32,849 : - EPOCH - 1 : training on 540242 raw words (486192 effective words) took 0.6s, 822110 effective words/s\n",
      "2021-09-15 18:18:33,546 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:33,577 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:33,578 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:33,579 : - EPOCH - 2 : training on 540242 raw words (486147 effective words) took 0.7s, 682359 effective words/s\n",
      "2021-09-15 18:18:34,169 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:34,174 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:34,185 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:34,186 : - EPOCH - 3 : training on 540242 raw words (486123 effective words) took 0.6s, 823135 effective words/s\n",
      "2021-09-15 18:18:34,707 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:34,712 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:34,740 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:34,742 : - EPOCH - 4 : training on 540242 raw words (486153 effective words) took 0.5s, 890143 effective words/s\n",
      "2021-09-15 18:18:35,227 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:35,233 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:35,243 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:35,244 : - EPOCH - 5 : training on 540242 raw words (486084 effective words) took 0.5s, 1040454 effective words/s\n",
      "2021-09-15 18:18:35,752 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:35,766 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:35,768 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:35,769 : - EPOCH - 6 : training on 540242 raw words (486218 effective words) took 0.5s, 951119 effective words/s\n",
      "2021-09-15 18:18:36,200 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:36,202 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:36,228 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:36,237 : - EPOCH - 7 : training on 540242 raw words (486214 effective words) took 0.5s, 1062287 effective words/s\n",
      "2021-09-15 18:18:36,761 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:36,767 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:36,772 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:36,773 : - EPOCH - 8 : training on 540242 raw words (486334 effective words) took 0.5s, 926276 effective words/s\n",
      "2021-09-15 18:18:37,309 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:37,316 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:37,329 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:37,330 : - EPOCH - 9 : training on 540242 raw words (486150 effective words) took 0.5s, 889184 effective words/s\n",
      "2021-09-15 18:18:37,843 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:37,849 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:37,859 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:37,861 : - EPOCH - 10 : training on 540242 raw words (486135 effective words) took 0.5s, 934194 effective words/s\n",
      "2021-09-15 18:18:38,269 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:38,279 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:38,282 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:38,284 : - EPOCH - 11 : training on 540242 raw words (485998 effective words) took 0.4s, 1182667 effective words/s\n",
      "2021-09-15 18:18:38,821 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:38,826 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:38,835 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:38,837 : - EPOCH - 12 : training on 540242 raw words (486284 effective words) took 0.5s, 896621 effective words/s\n",
      "2021-09-15 18:18:39,471 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:39,477 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:39,490 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:39,491 : - EPOCH - 13 : training on 540242 raw words (486138 effective words) took 0.6s, 762474 effective words/s\n",
      "2021-09-15 18:18:39,990 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:39,997 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:40,003 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:40,005 : - EPOCH - 14 : training on 540242 raw words (486228 effective words) took 0.5s, 974905 effective words/s\n",
      "2021-09-15 18:18:40,504 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:40,505 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:40,512 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:40,514 : - EPOCH - 15 : training on 540242 raw words (486051 effective words) took 0.5s, 980911 effective words/s\n",
      "2021-09-15 18:18:41,074 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:41,085 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:41,088 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:41,090 : - EPOCH - 16 : training on 540242 raw words (486129 effective words) took 0.6s, 860423 effective words/s\n",
      "2021-09-15 18:18:41,803 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:41,805 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:41,820 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:41,822 : - EPOCH - 17 : training on 540242 raw words (486200 effective words) took 0.7s, 677653 effective words/s\n",
      "2021-09-15 18:18:42,604 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:42,611 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:42,631 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:42,632 : - EPOCH - 18 : training on 540242 raw words (486069 effective words) took 0.8s, 611557 effective words/s\n",
      "2021-09-15 18:18:43,385 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:43,405 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:43,431 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:43,436 : - EPOCH - 19 : training on 540242 raw words (486103 effective words) took 0.8s, 615298 effective words/s\n",
      "2021-09-15 18:18:44,461 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:44,485 : - EPOCH 20 - PROGRESS: at 98.14% examples, 466747 words/s, in_qsize 1, out_qsize 1\n",
      "2021-09-15 18:18:44,487 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:44,489 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:44,491 : - EPOCH - 20 : training on 540242 raw words (486007 effective words) took 1.0s, 472267 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:18:45,102 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:45,106 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:45,128 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:45,130 : - EPOCH - 21 : training on 540242 raw words (486133 effective words) took 0.6s, 776824 effective words/s\n",
      "2021-09-15 18:18:45,894 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:45,906 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:45,915 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:45,917 : - EPOCH - 22 : training on 540242 raw words (486111 effective words) took 0.8s, 630767 effective words/s\n",
      "2021-09-15 18:18:46,508 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:46,521 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:46,528 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:46,529 : - EPOCH - 23 : training on 540242 raw words (486072 effective words) took 0.6s, 809312 effective words/s\n",
      "2021-09-15 18:18:47,129 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:47,148 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:47,150 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:47,152 : - EPOCH - 24 : training on 540242 raw words (486176 effective words) took 0.6s, 801172 effective words/s\n",
      "2021-09-15 18:18:47,734 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:47,753 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:47,755 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:47,756 : - EPOCH - 25 : training on 540242 raw words (486102 effective words) took 0.6s, 824723 effective words/s\n",
      "2021-09-15 18:18:48,386 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:48,394 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:48,410 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:48,412 : - EPOCH - 26 : training on 540242 raw words (486218 effective words) took 0.6s, 756949 effective words/s\n",
      "2021-09-15 18:18:49,012 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:49,019 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:49,028 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:49,030 : - EPOCH - 27 : training on 540242 raw words (486124 effective words) took 0.6s, 803827 effective words/s\n",
      "2021-09-15 18:18:49,642 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:49,660 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:49,662 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:49,664 : - EPOCH - 28 : training on 540242 raw words (486138 effective words) took 0.6s, 780636 effective words/s\n",
      "2021-09-15 18:18:50,297 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:50,300 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:50,315 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:50,317 : - EPOCH - 29 : training on 540242 raw words (486096 effective words) took 0.6s, 756684 effective words/s\n",
      "2021-09-15 18:18:50,947 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:18:50,958 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:18:50,960 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:18:50,961 : - EPOCH - 30 : training on 540242 raw words (486200 effective words) took 0.6s, 767144 effective words/s\n",
      "2021-09-15 18:18:50,963 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584327 effective words) took 18.7s, 778829 effective words/s', 'datetime': '2021-09-15T18:18:50.963256', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584327, 16207260)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens, \n",
    "                 total_examples=w2v_modelo.corpus_count,\n",
    "                 epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a9d4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tornozeleiras', 0.6468854546546936),\n",
       " ('varejistas', 0.6299357414245605),\n",
       " ('leniência', 0.6258296370506287),\n",
       " ('kraft', 0.6175836324691772),\n",
       " ('invepar', 0.6105926632881165),\n",
       " ('telecomunicações', 0.6027239561080933),\n",
       " ('sabmiller', 0.5957454442977905),\n",
       " ('citibank', 0.5954554080963135),\n",
       " ('negociam', 0.5772911906242371),\n",
       " ('braskem', 0.577210545539856)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Avaliação Qualitativa\n",
    "w2v_modelo.wv.most_similar(\"pfizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f6bca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unilever', 0.5758864879608154),\n",
       " ('amazon', 0.572556734085083),\n",
       " ('buffett', 0.5339102745056152),\n",
       " ('sony', 0.5299050211906433),\n",
       " ('viajante', 0.5268521308898926),\n",
       " ('ikea', 0.5176929235458374),\n",
       " ('sky', 0.511826753616333),\n",
       " ('lego', 0.5113440155982971),\n",
       " ('editora', 0.5045936107635498),\n",
       " ('tesla', 0.501508891582489)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Análise Qualitativa\n",
    "w2v_modelo.wv.most_similar(\"microsoft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b08a539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:32:33,160 : - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=100, alpha=0.03)', 'datetime': '2021-09-15T18:32:33.159991', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'created'}\n",
      "2021-09-15 18:32:33,163 : - collecting all words and their counts\n",
      "2021-09-15 18:32:33,164 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-15 18:32:33,178 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2021-09-15 18:32:33,198 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2021-09-15 18:32:33,213 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2021-09-15 18:32:33,226 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2021-09-15 18:32:33,242 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2021-09-15 18:32:33,264 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2021-09-15 18:32:33,287 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2021-09-15 18:32:33,301 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2021-09-15 18:32:33,319 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2021-09-15 18:32:33,341 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2021-09-15 18:32:33,354 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2021-09-15 18:32:33,374 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2021-09-15 18:32:33,392 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2021-09-15 18:32:33,412 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2021-09-15 18:32:33,432 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2021-09-15 18:32:33,451 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2021-09-15 18:32:33,464 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2021-09-15 18:32:33,466 : - Creating a fresh vocabulary\n",
      "2021-09-15 18:32:33,548 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.559897211095155%% of original 39693, drops 26769)', 'datetime': '2021-09-15T18:32:33.548696', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-15 18:32:33,549 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.66688261927062%% of original 540242, drops 45019)', 'datetime': '2021-09-15T18:32:33.549372', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-15 18:32:33,634 : - deleting the raw counts dictionary of 39693 items\n",
      "2021-09-15 18:32:33,635 : - sample=0.001 downsamples 8 most-common words\n",
      "2021-09-15 18:32:33,636 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2021-09-15T18:32:33.636354', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-15 18:32:33,775 : - estimated required memory for 12924 words and 100 dimensions: 16801200 bytes\n",
      "2021-09-15 18:32:33,776 : - resetting layer weights\n",
      "2021-09-15 18:32:33,791 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-15T18:32:33.791019', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'build_vocab'}\n",
      "2021-09-15 18:32:33,795 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-15T18:32:33.795428', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n",
      "2021-09-15 18:32:34,606 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:34,619 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:34,629 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:34,630 : - EPOCH - 1 : training on 540242 raw words (486063 effective words) took 0.8s, 595955 effective words/s\n",
      "2021-09-15 18:32:35,643 : - EPOCH 2 - PROGRESS: at 87.00% examples, 421691 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:35,716 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:35,731 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:35,752 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:35,754 : - EPOCH - 2 : training on 540242 raw words (486094 effective words) took 1.1s, 436877 effective words/s\n",
      "2021-09-15 18:32:36,686 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:36,712 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:36,729 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:36,731 : - EPOCH - 3 : training on 540242 raw words (486146 effective words) took 1.0s, 511227 effective words/s\n",
      "2021-09-15 18:32:37,746 : - EPOCH 4 - PROGRESS: at 83.29% examples, 402722 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:37,868 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:37,902 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:37,908 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:37,910 : - EPOCH - 4 : training on 540242 raw words (486254 effective words) took 1.2s, 416002 effective words/s\n",
      "2021-09-15 18:32:38,909 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:38,932 : - EPOCH 5 - PROGRESS: at 98.14% examples, 474416 words/s, in_qsize 1, out_qsize 1\n",
      "2021-09-15 18:32:38,933 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:38,955 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:38,960 : - EPOCH - 5 : training on 540242 raw words (486049 effective words) took 1.0s, 470404 effective words/s\n",
      "2021-09-15 18:32:39,982 : - EPOCH 6 - PROGRESS: at 59.32% examples, 284696 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:40,342 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:40,381 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:40,385 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:40,386 : - EPOCH - 6 : training on 540242 raw words (486107 effective words) took 1.4s, 343555 effective words/s\n",
      "2021-09-15 18:32:41,413 : - EPOCH 7 - PROGRESS: at 90.67% examples, 435091 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:41,525 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:41,546 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:41,548 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:41,549 : - EPOCH - 7 : training on 540242 raw words (486130 effective words) took 1.1s, 423044 effective words/s\n",
      "2021-09-15 18:32:42,567 : - EPOCH 8 - PROGRESS: at 77.75% examples, 375136 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-15 18:32:42,725 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:42,757 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:42,759 : - worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:32:42,760 : - EPOCH - 8 : training on 540242 raw words (486138 effective words) took 1.2s, 404918 effective words/s\n",
      "2021-09-15 18:32:43,775 : - EPOCH 9 - PROGRESS: at 94.38% examples, 456245 words/s, in_qsize 4, out_qsize 0\n",
      "2021-09-15 18:32:43,814 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:43,825 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:43,836 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:43,837 : - EPOCH - 9 : training on 540242 raw words (486170 effective words) took 1.1s, 455080 effective words/s\n",
      "2021-09-15 18:32:44,853 : - EPOCH 10 - PROGRESS: at 77.75% examples, 375424 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:45,139 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:45,145 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:45,163 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:45,166 : - EPOCH - 10 : training on 540242 raw words (486125 effective words) took 1.3s, 368584 effective words/s\n",
      "2021-09-15 18:32:46,206 : - EPOCH 11 - PROGRESS: at 62.98% examples, 297565 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:46,674 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:46,678 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:46,686 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:46,688 : - EPOCH - 11 : training on 540242 raw words (486094 effective words) took 1.5s, 322042 effective words/s\n",
      "2021-09-15 18:32:47,713 : - EPOCH 12 - PROGRESS: at 68.53% examples, 328487 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:48,152 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:48,186 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:48,214 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:48,217 : - EPOCH - 12 : training on 540242 raw words (486024 effective words) took 1.5s, 320375 effective words/s\n",
      "2021-09-15 18:32:49,238 : - EPOCH 13 - PROGRESS: at 59.29% examples, 285042 words/s, in_qsize 4, out_qsize 1\n",
      "2021-09-15 18:32:49,933 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:49,941 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:49,956 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:49,958 : - EPOCH - 13 : training on 540242 raw words (486081 effective words) took 1.7s, 280970 effective words/s\n",
      "2021-09-15 18:32:50,976 : - EPOCH 14 - PROGRESS: at 66.69% examples, 321402 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:51,403 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:51,414 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:51,431 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:51,433 : - EPOCH - 14 : training on 540242 raw words (486039 effective words) took 1.5s, 331959 effective words/s\n",
      "2021-09-15 18:32:52,467 : - EPOCH 15 - PROGRESS: at 62.98% examples, 299199 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-15 18:32:52,990 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:52,995 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:53,008 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:53,011 : - EPOCH - 15 : training on 540242 raw words (486250 effective words) took 1.6s, 310306 effective words/s\n",
      "2021-09-15 18:32:54,031 : - EPOCH 16 - PROGRESS: at 62.98% examples, 305562 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-15 18:32:54,500 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:54,552 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:54,568 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:54,569 : - EPOCH - 16 : training on 540242 raw words (486123 effective words) took 1.5s, 316005 effective words/s\n",
      "2021-09-15 18:32:55,614 : - EPOCH 17 - PROGRESS: at 74.06% examples, 348477 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-15 18:32:55,966 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:55,984 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:55,986 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:55,988 : - EPOCH - 17 : training on 540242 raw words (486124 effective words) took 1.4s, 345824 effective words/s\n",
      "2021-09-15 18:32:57,015 : - EPOCH 18 - PROGRESS: at 55.60% examples, 266613 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:57,719 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:57,750 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:57,753 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:57,755 : - EPOCH - 18 : training on 540242 raw words (486039 effective words) took 1.8s, 277465 effective words/s\n",
      "2021-09-15 18:32:58,777 : - EPOCH 19 - PROGRESS: at 70.35% examples, 338587 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:32:59,132 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:32:59,152 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:32:59,182 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:32:59,184 : - EPOCH - 19 : training on 540242 raw words (486145 effective words) took 1.4s, 343095 effective words/s\n",
      "2021-09-15 18:33:00,224 : - EPOCH 20 - PROGRESS: at 68.53% examples, 324125 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:00,630 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:00,669 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:00,681 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:00,682 : - EPOCH - 20 : training on 540242 raw words (486157 effective words) took 1.5s, 327321 effective words/s\n",
      "2021-09-15 18:33:01,707 : - EPOCH 21 - PROGRESS: at 66.69% examples, 321553 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:02,174 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:02,202 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:02,221 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:02,222 : - EPOCH - 21 : training on 540242 raw words (486169 effective words) took 1.5s, 319380 effective words/s\n",
      "2021-09-15 18:33:03,273 : - EPOCH 22 - PROGRESS: at 57.46% examples, 268478 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:03,923 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:03,971 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:03,993 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:03,995 : - EPOCH - 22 : training on 540242 raw words (486200 effective words) took 1.8s, 276229 effective words/s\n",
      "2021-09-15 18:33:05,019 : - EPOCH 23 - PROGRESS: at 53.76% examples, 258071 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:05,674 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:05,719 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:05,759 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:05,761 : - EPOCH - 23 : training on 540242 raw words (486244 effective words) took 1.8s, 277388 effective words/s\n",
      "2021-09-15 18:33:06,798 : - EPOCH 24 - PROGRESS: at 53.76% examples, 255750 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:07,391 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:07,454 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:07,457 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:07,459 : - EPOCH - 24 : training on 540242 raw words (486100 effective words) took 1.7s, 289134 effective words/s\n",
      "2021-09-15 18:33:08,501 : - EPOCH 25 - PROGRESS: at 74.06% examples, 349182 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:33:08,793 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:08,816 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:08,836 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:08,837 : - EPOCH - 25 : training on 540242 raw words (486131 effective words) took 1.4s, 355750 effective words/s\n",
      "2021-09-15 18:33:09,858 : - EPOCH 26 - PROGRESS: at 70.35% examples, 338083 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:10,204 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:10,222 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:10,241 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:10,242 : - EPOCH - 26 : training on 540242 raw words (486131 effective words) took 1.4s, 348332 effective words/s\n",
      "2021-09-15 18:33:11,266 : - EPOCH 27 - PROGRESS: at 68.53% examples, 329505 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:11,783 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:11,843 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:11,848 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:11,850 : - EPOCH - 27 : training on 540242 raw words (486183 effective words) took 1.6s, 304974 effective words/s\n",
      "2021-09-15 18:33:12,867 : - EPOCH 28 - PROGRESS: at 62.98% examples, 303873 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:13,312 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:13,334 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:13,339 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:13,342 : - EPOCH - 28 : training on 540242 raw words (486042 effective words) took 1.5s, 328286 effective words/s\n",
      "2021-09-15 18:33:14,376 : - EPOCH 29 - PROGRESS: at 70.35% examples, 334066 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:14,781 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:14,832 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:14,837 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:14,838 : - EPOCH - 29 : training on 540242 raw words (486160 effective words) took 1.5s, 327371 effective words/s\n",
      "2021-09-15 18:33:15,851 : - EPOCH 30 - PROGRESS: at 61.16% examples, 296662 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-15 18:33:16,487 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-15 18:33:16,528 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-15 18:33:16,561 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-15 18:33:16,563 : - EPOCH - 30 : training on 540242 raw words (486052 effective words) took 1.7s, 283870 effective words/s\n",
      "2021-09-15 18:33:16,564 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14583764 effective words) took 42.8s, 341023 effective words/s', 'datetime': '2021-09-15T18:33:16.564714', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14583764, 16207260)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treinamento do modelo Skip-gram\n",
    "# Skip-Gram possui um resultado melhor com um window maior, por isso, alterado de 2 para 5\n",
    "\n",
    "w2v_modelo_sg = Word2Vec(sg = 1,\n",
    "                     window = 5,\n",
    "                     #size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)\n",
    "\n",
    "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
    "\n",
    "w2v_modelo_sg.train(lista_lista_tokens,\n",
    "                 total_examples=w2v_modelo_sg.corpus_count,\n",
    "                 epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96aba9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('facebook', 0.680336594581604),\n",
       " ('apple', 0.6156793236732483),\n",
       " ('chips', 0.5675997138023376),\n",
       " ('reguladores', 0.5611848831176758),\n",
       " ('amazon', 0.549229621887207),\n",
       " ('android', 0.5440897941589355),\n",
       " ('volkswagen', 0.5362513661384583),\n",
       " ('waze', 0.5348283648490906),\n",
       " ('concorda', 0.5347558856010437),\n",
       " ('buffett', 0.5292649269104004)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c943d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5ca69ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'artigo_treino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/2877845315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatriz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmatriz_vetores_treino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatriz_vetores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martigo_treino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmatriz_vetores_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatriz_vetores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martigo_treino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatriz_vetores_treino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'artigo_treino' is not defined"
     ]
    }
   ],
   "source": [
    "def matriz_vetores(textos):\n",
    "    x = len(textos)\n",
    "    y = 300\n",
    "    matriz = np.zeros((x,y))\n",
    "    \n",
    "    for i in range(x):\n",
    "        palavras_numeros = tokenizador(textos.iloc[i])\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(palavras_numeros)\n",
    "        \n",
    "    return matriz\n",
    "\n",
    "matriz_vetores_treino = matriz_vetores(artigo_treino.title)\n",
    "matriz_vetores_teste = matriz_vetores(artigo_treino.title)\n",
    "print(matriz_vetores_treino)\n",
    "print(matriz_vetores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinacao_vetores_por_soma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98c91945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:41:28,433 : - storing 12924x100 projection weights into modelos/modelo_cbow.txt\n",
      "2021-09-15 18:41:29,769 : - storing 12924x100 projection weights into modelos/modelo_skipgram.txt\n"
     ]
    }
   ],
   "source": [
    "w2v_modelo.wv.save_word2vec_format(\"modelos/modelo_cbow.txt\", binary=False)\n",
    "w2v_modelo_sg.wv.save_word2vec_format(\"modelos/modelo_skipgram.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c0a6265",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/local/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/3235702663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlista_alfanumerico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtokenizador\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Texto Exemplo, 1234.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_33/3235702663.py\u001b[0m in \u001b[0;36mtokenizador\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlista_alfanumerico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken_valido\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_valido\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mponctuation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlista_alfanumerico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_valido\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     return [\n\u001b[1;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/local/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "def tokenizador(texto):\n",
    "    texto = texto.lower()\n",
    "    lista_alfanumerico = []\n",
    "    \n",
    "    for token_valido in nltk.word_tokenize(texto):\n",
    "        if token_valido in string.ponctuation: continue\n",
    "        lista_alfanumerico.append(token_valido)\n",
    "            \n",
    "    return lista_alfanumerico\n",
    "\n",
    "tokenizador(\"Texto Exemplo, 1234.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a9025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
