{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c09bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456428e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a29447e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
       "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
       "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
       "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
       "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
       "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
       "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
       "2  Apesar de larga vitória nas legislativas, Macr...   \n",
       "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
       "4  Após queda em maio, a atividade econômica sobe...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
       "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
       "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
       "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
       "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
       "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino = pd.read_csv(\"data/treino.csv\")\n",
    "dados_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7abc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Rio de !!!janeiro$$$$$ é uma cidade maravilhosa\"\n",
    "doc = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ea52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b8529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_textos(doc):\n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text)\n",
    "        \n",
    "    if len(tokens_validos) > 2:\n",
    "        return \" \".join(tokens_validos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6e6135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rio cidade maravilhosa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trata_textos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c2feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18006778160731\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# pegar o início da execução (para calcular o tempo levado para o processamento)\n",
    "t0 = time()\n",
    "\n",
    "# processar em paralelo e enviar em lotes\n",
    "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
    "                                                       batch_size = 1000,\n",
    "                                                       n_process = -1)]\n",
    "\n",
    "tf = time() - t0\n",
    "\n",
    "print(tf/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c023d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queda maio atividade econômica sobe junho bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo\n",
       "0  polêmica marine le pen abomina negacionistas h...\n",
       "1  macron le pen turno frança revés siglas tradic...\n",
       "2  apesar larga vitória legislativas macron terá ...\n",
       "3  governo antecipa balanço alckmin anuncia queda...\n",
       "4       queda maio atividade econômica sobe junho bc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_tratados = pd.DataFrame({\"titulo\":textos_tratados})\n",
    "\n",
    "titulos_tratados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2639af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0,\n",
    "                     window = 2,\n",
    "                     #size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c89fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f7a0ace0a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3546e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "84466\n"
     ]
    }
   ],
   "source": [
    "print(len(titulos_tratados))\n",
    "\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
    "\n",
    "print(len(titulos_tratados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51684a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d948142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:52:02,265 : - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=100, alpha=0.03)', 'datetime': '2021-09-18T18:52:02.265406', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'created'}\n",
      "2021-09-18 18:52:02,268 : - collecting all words and their counts\n",
      "2021-09-18 18:52:02,269 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-18 18:52:02,299 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2021-09-18 18:52:02,318 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2021-09-18 18:52:02,341 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2021-09-18 18:52:02,360 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2021-09-18 18:52:02,381 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2021-09-18 18:52:02,402 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2021-09-18 18:52:02,422 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2021-09-18 18:52:02,437 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2021-09-18 18:52:02,476 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2021-09-18 18:52:02,511 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2021-09-18 18:52:02,552 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2021-09-18 18:52:02,588 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2021-09-18 18:52:02,612 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2021-09-18 18:52:02,634 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2021-09-18 18:52:02,654 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2021-09-18 18:52:02,679 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2021-09-18 18:52:02,698 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2021-09-18 18:52:02,699 : - Creating a fresh vocabulary\n",
      "2021-09-18 18:52:02,846 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.559897211095155%% of original 39693, drops 26769)', 'datetime': '2021-09-18T18:52:02.846699', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-18 18:52:02,848 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.66688261927062%% of original 540242, drops 45019)', 'datetime': '2021-09-18T18:52:02.848138', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-18 18:52:03,009 : - deleting the raw counts dictionary of 39693 items\n",
      "2021-09-18 18:52:03,014 : - sample=0.001 downsamples 8 most-common words\n",
      "2021-09-18 18:52:03,016 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2021-09-18T18:52:03.016208', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-18 18:52:03,301 : - estimated required memory for 12924 words and 100 dimensions: 16801200 bytes\n",
      "2021-09-18 18:52:03,303 : - resetting layer weights\n",
      "2021-09-18 18:52:03,318 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-18T18:52:03.318802', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0,\n",
    "                     window = 2,\n",
    "                     #size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)\n",
    "\n",
    "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e8f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:52:03,333 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2021-09-18T18:52:03.332999', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n",
      "2021-09-18 18:52:04,214 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:04,218 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:04,243 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:04,245 : - EPOCH - 1 : training on 540242 raw words (486133 effective words) took 0.9s, 547590 effective words/s\n",
      "2021-09-18 18:52:05,199 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:05,221 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:05,224 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:05,226 : - EPOCH - 2 : training on 540242 raw words (486029 effective words) took 1.0s, 503050 effective words/s\n",
      "2021-09-18 18:52:05,988 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:06,005 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:06,008 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:06,009 : - EPOCH - 3 : training on 540242 raw words (486191 effective words) took 0.8s, 631555 effective words/s\n",
      "2021-09-18 18:52:06,633 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:06,635 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:06,647 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:06,648 : - EPOCH - 4 : training on 540242 raw words (486238 effective words) took 0.6s, 773887 effective words/s\n",
      "2021-09-18 18:52:07,206 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:07,218 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:07,222 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:07,223 : - EPOCH - 5 : training on 540242 raw words (486099 effective words) took 0.6s, 860421 effective words/s\n",
      "2021-09-18 18:52:07,757 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:07,763 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:07,775 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:07,776 : - EPOCH - 6 : training on 540242 raw words (486119 effective words) took 0.5s, 894289 effective words/s\n",
      "2021-09-18 18:52:08,297 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:08,303 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:08,313 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:08,315 : - EPOCH - 7 : training on 540242 raw words (486090 effective words) took 0.5s, 922063 effective words/s\n",
      "2021-09-18 18:52:08,878 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:08,882 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:08,899 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:08,901 : - EPOCH - 8 : training on 540242 raw words (486269 effective words) took 0.6s, 843536 effective words/s\n",
      "2021-09-18 18:52:09,414 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:09,421 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:09,436 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:09,437 : - EPOCH - 9 : training on 540242 raw words (486020 effective words) took 0.5s, 927227 effective words/s\n",
      "2021-09-18 18:52:09,987 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:09,993 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:10,003 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:10,005 : - EPOCH - 10 : training on 540242 raw words (486155 effective words) took 0.6s, 876249 effective words/s\n",
      "2021-09-18 18:52:10,526 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:10,533 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:10,543 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:10,545 : - EPOCH - 11 : training on 540242 raw words (486015 effective words) took 0.5s, 914985 effective words/s\n",
      "2021-09-18 18:52:11,133 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:11,136 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:11,153 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:11,155 : - EPOCH - 12 : training on 540242 raw words (486208 effective words) took 0.6s, 811843 effective words/s\n",
      "2021-09-18 18:52:11,699 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:11,714 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:11,716 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:11,717 : - EPOCH - 13 : training on 540242 raw words (486056 effective words) took 0.6s, 879894 effective words/s\n",
      "2021-09-18 18:52:12,296 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:12,308 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:12,314 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:12,315 : - EPOCH - 14 : training on 540242 raw words (486209 effective words) took 0.6s, 827853 effective words/s\n",
      "2021-09-18 18:52:12,852 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:12,861 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:12,868 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:12,869 : - EPOCH - 15 : training on 540242 raw words (486166 effective words) took 0.5s, 893602 effective words/s\n",
      "2021-09-18 18:52:13,412 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:13,426 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:13,432 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:13,433 : - EPOCH - 16 : training on 540242 raw words (486157 effective words) took 0.6s, 877812 effective words/s\n",
      "2021-09-18 18:52:13,988 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:13,997 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:14,006 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:14,007 : - EPOCH - 17 : training on 540242 raw words (486153 effective words) took 0.6s, 866201 effective words/s\n",
      "2021-09-18 18:52:14,548 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:14,554 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:14,567 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:14,569 : - EPOCH - 18 : training on 540242 raw words (486119 effective words) took 0.6s, 882220 effective words/s\n",
      "2021-09-18 18:52:15,109 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:15,122 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:15,130 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:15,132 : - EPOCH - 19 : training on 540242 raw words (486164 effective words) took 0.6s, 881076 effective words/s\n",
      "2021-09-18 18:52:15,736 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:15,738 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:15,749 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:15,751 : - EPOCH - 20 : training on 540242 raw words (486182 effective words) took 0.6s, 799766 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:52:16,292 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:16,301 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:16,305 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:16,306 : - EPOCH - 21 : training on 540242 raw words (486236 effective words) took 0.5s, 890523 effective words/s\n",
      "2021-09-18 18:52:16,892 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:16,903 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:16,910 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:16,911 : - EPOCH - 22 : training on 540242 raw words (486072 effective words) took 0.6s, 817504 effective words/s\n",
      "2021-09-18 18:52:17,445 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:17,453 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:17,467 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:17,469 : - EPOCH - 23 : training on 540242 raw words (486094 effective words) took 0.5s, 886444 effective words/s\n",
      "2021-09-18 18:52:18,051 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:18,059 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:18,073 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:18,074 : - EPOCH - 24 : training on 540242 raw words (486101 effective words) took 0.6s, 817571 effective words/s\n",
      "2021-09-18 18:52:18,645 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:18,657 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:18,666 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:18,668 : - EPOCH - 25 : training on 540242 raw words (486230 effective words) took 0.6s, 833153 effective words/s\n",
      "2021-09-18 18:52:19,208 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:19,212 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:19,224 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:19,226 : - EPOCH - 26 : training on 540242 raw words (486161 effective words) took 0.5s, 889945 effective words/s\n",
      "2021-09-18 18:52:19,767 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:19,781 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:19,782 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:19,784 : - EPOCH - 27 : training on 540242 raw words (486134 effective words) took 0.5s, 886526 effective words/s\n",
      "2021-09-18 18:52:20,340 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:20,345 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:20,354 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:20,356 : - EPOCH - 28 : training on 540242 raw words (486173 effective words) took 0.6s, 866153 effective words/s\n",
      "2021-09-18 18:52:20,842 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:20,850 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:20,859 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:20,860 : - EPOCH - 29 : training on 540242 raw words (486120 effective words) took 0.5s, 983793 effective words/s\n",
      "2021-09-18 18:52:21,388 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:21,398 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:21,404 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:21,406 : - EPOCH - 30 : training on 540242 raw words (486112 effective words) took 0.5s, 907441 effective words/s\n",
      "2021-09-18 18:52:21,407 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584205 effective words) took 18.1s, 807189 effective words/s', 'datetime': '2021-09-18T18:52:21.407792', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584205, 16207260)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens, \n",
    "                 total_examples=w2v_modelo.corpus_count,\n",
    "                 epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a9d4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tornozeleiras', 0.6402171850204468),\n",
       " ('varejistas', 0.6213124990463257),\n",
       " ('invepar', 0.6192618012428284),\n",
       " ('kraft', 0.6191898584365845),\n",
       " ('telefónica', 0.6007035970687866),\n",
       " ('lucram', 0.5959634184837341),\n",
       " ('leniência', 0.5940981507301331),\n",
       " ('cetip', 0.5926719307899475),\n",
       " ('negociam', 0.5741658210754395),\n",
       " ('braskem', 0.5734907984733582)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Avaliação Qualitativa\n",
    "w2v_modelo.wv.most_similar(\"pfizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6bca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unilever', 0.5596420168876648),\n",
       " ('sky', 0.5520409345626831),\n",
       " ('amazon', 0.5504106283187866),\n",
       " ('tesla', 0.5415129065513611),\n",
       " ('canais', 0.5408347845077515),\n",
       " ('braskem', 0.5335578918457031),\n",
       " ('sony', 0.513820230960846),\n",
       " ('buffett', 0.494262158870697),\n",
       " ('walmart', 0.4938730001449585),\n",
       " ('disney', 0.48963168263435364)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Análise Qualitativa\n",
    "w2v_modelo.wv.most_similar(\"microsoft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b08a539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:52:21,546 : - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=100, alpha=0.03)', 'datetime': '2021-09-18T18:52:21.546225', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'created'}\n",
      "2021-09-18 18:52:21,549 : - collecting all words and their counts\n",
      "2021-09-18 18:52:21,552 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-18 18:52:21,575 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2021-09-18 18:52:21,605 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2021-09-18 18:52:21,625 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2021-09-18 18:52:21,646 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2021-09-18 18:52:21,666 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2021-09-18 18:52:21,686 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2021-09-18 18:52:21,707 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2021-09-18 18:52:21,733 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2021-09-18 18:52:21,756 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2021-09-18 18:52:21,777 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2021-09-18 18:52:21,801 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2021-09-18 18:52:21,820 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2021-09-18 18:52:21,844 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2021-09-18 18:52:21,867 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2021-09-18 18:52:21,888 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2021-09-18 18:52:21,914 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2021-09-18 18:52:21,936 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2021-09-18 18:52:21,937 : - Creating a fresh vocabulary\n",
      "2021-09-18 18:52:22,056 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.559897211095155%% of original 39693, drops 26769)', 'datetime': '2021-09-18T18:52:22.056940', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-18 18:52:22,058 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.66688261927062%% of original 540242, drops 45019)', 'datetime': '2021-09-18T18:52:22.058060', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-18 18:52:22,203 : - deleting the raw counts dictionary of 39693 items\n",
      "2021-09-18 18:52:22,205 : - sample=0.001 downsamples 8 most-common words\n",
      "2021-09-18 18:52:22,206 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2021-09-18T18:52:22.206673', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'prepare_vocab'}\n",
      "2021-09-18 18:52:22,412 : - estimated required memory for 12924 words and 100 dimensions: 16801200 bytes\n",
      "2021-09-18 18:52:22,413 : - resetting layer weights\n",
      "2021-09-18 18:52:22,426 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-18T18:52:22.426379', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'build_vocab'}\n",
      "2021-09-18 18:52:22,428 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-18T18:52:22.427971', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n",
      "2021-09-18 18:52:23,443 : - EPOCH 1 - PROGRESS: at 83.29% examples, 402200 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-18 18:52:23,606 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:23,626 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:23,656 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:23,657 : - EPOCH - 1 : training on 540242 raw words (486103 effective words) took 1.2s, 398316 effective words/s\n",
      "2021-09-18 18:52:24,670 : - EPOCH 2 - PROGRESS: at 77.75% examples, 377244 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:24,912 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:24,915 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:24,953 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:24,955 : - EPOCH - 2 : training on 540242 raw words (485929 effective words) took 1.3s, 377751 effective words/s\n",
      "2021-09-18 18:52:25,970 : - EPOCH 3 - PROGRESS: at 77.75% examples, 375719 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-18 18:52:26,188 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:26,234 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:26,250 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:26,252 : - EPOCH - 3 : training on 540242 raw words (486085 effective words) took 1.3s, 377628 effective words/s\n",
      "2021-09-18 18:52:27,293 : - EPOCH 4 - PROGRESS: at 79.60% examples, 376191 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:27,502 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:27,525 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:27,538 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:27,539 : - EPOCH - 4 : training on 540242 raw words (486229 effective words) took 1.3s, 381423 effective words/s\n",
      "2021-09-18 18:52:28,570 : - EPOCH 5 - PROGRESS: at 75.91% examples, 361921 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:28,796 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:28,852 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:28,855 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:28,856 : - EPOCH - 5 : training on 540242 raw words (486225 effective words) took 1.3s, 372575 effective words/s\n",
      "2021-09-18 18:52:29,897 : - EPOCH 6 - PROGRESS: at 79.60% examples, 375530 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:30,105 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:30,135 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:30,145 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:30,148 : - EPOCH - 6 : training on 540242 raw words (486183 effective words) took 1.3s, 379704 effective words/s\n",
      "2021-09-18 18:52:31,161 : - EPOCH 7 - PROGRESS: at 75.91% examples, 367948 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:31,417 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:31,435 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:31,470 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:31,472 : - EPOCH - 7 : training on 540242 raw words (486202 effective words) took 1.3s, 370230 effective words/s\n",
      "2021-09-18 18:52:32,491 : - EPOCH 8 - PROGRESS: at 72.19% examples, 347886 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:52:32,820 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:32,828 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:32,842 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:32,844 : - EPOCH - 8 : training on 540242 raw words (486165 effective words) took 1.4s, 357150 effective words/s\n",
      "2021-09-18 18:52:33,861 : - EPOCH 9 - PROGRESS: at 75.91% examples, 367189 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-18 18:52:34,095 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:34,146 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:34,159 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:34,160 : - EPOCH - 9 : training on 540242 raw words (486113 effective words) took 1.3s, 373034 effective words/s\n",
      "2021-09-18 18:52:35,186 : - EPOCH 10 - PROGRESS: at 77.75% examples, 372676 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:35,436 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:35,438 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:35,472 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:35,474 : - EPOCH - 10 : training on 540242 raw words (486085 effective words) took 1.3s, 373453 effective words/s\n",
      "2021-09-18 18:52:36,507 : - EPOCH 11 - PROGRESS: at 75.91% examples, 360472 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:36,762 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:36,792 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:36,809 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:36,810 : - EPOCH - 11 : training on 540242 raw words (486086 effective words) took 1.3s, 366505 effective words/s\n",
      "2021-09-18 18:52:37,830 : - EPOCH 12 - PROGRESS: at 79.60% examples, 382979 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-18 18:52:38,026 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:38,058 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:38,067 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:38,068 : - EPOCH - 12 : training on 540242 raw words (486145 effective words) took 1.2s, 389499 effective words/s\n",
      "2021-09-18 18:52:39,089 : - EPOCH 13 - PROGRESS: at 81.44% examples, 391121 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:39,254 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:39,287 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:39,315 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:39,316 : - EPOCH - 13 : training on 540242 raw words (486175 effective words) took 1.2s, 392622 effective words/s\n",
      "2021-09-18 18:52:40,331 : - EPOCH 14 - PROGRESS: at 75.91% examples, 366978 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:40,581 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:40,600 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:40,605 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:40,607 : - EPOCH - 14 : training on 540242 raw words (486147 effective words) took 1.3s, 379288 effective words/s\n",
      "2021-09-18 18:52:41,629 : - EPOCH 15 - PROGRESS: at 79.60% examples, 383510 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:41,829 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:41,859 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:41,863 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:41,865 : - EPOCH - 15 : training on 540242 raw words (486142 effective words) took 1.2s, 390799 effective words/s\n",
      "2021-09-18 18:52:42,894 : - EPOCH 16 - PROGRESS: at 79.60% examples, 379454 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:43,090 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:43,100 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:43,107 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:43,109 : - EPOCH - 16 : training on 540242 raw words (486167 effective words) took 1.2s, 393789 effective words/s\n",
      "2021-09-18 18:52:44,125 : - EPOCH 17 - PROGRESS: at 79.60% examples, 384344 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-18 18:52:44,328 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:44,350 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:44,365 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:44,367 : - EPOCH - 17 : training on 540242 raw words (486126 effective words) took 1.2s, 389334 effective words/s\n",
      "2021-09-18 18:52:45,401 : - EPOCH 18 - PROGRESS: at 81.44% examples, 385906 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:45,555 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:45,590 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:45,607 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:45,608 : - EPOCH - 18 : training on 540242 raw words (486081 effective words) took 1.2s, 394231 effective words/s\n",
      "2021-09-18 18:52:46,627 : - EPOCH 19 - PROGRESS: at 79.60% examples, 383419 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:46,823 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:46,834 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:46,847 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:46,848 : - EPOCH - 19 : training on 540242 raw words (486091 effective words) took 1.2s, 395068 effective words/s\n",
      "2021-09-18 18:52:47,895 : - EPOCH 20 - PROGRESS: at 79.60% examples, 372639 words/s, in_qsize 6, out_qsize 0\n",
      "2021-09-18 18:52:48,086 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:48,103 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:48,116 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:48,117 : - EPOCH - 20 : training on 540242 raw words (486101 effective words) took 1.3s, 385778 effective words/s\n",
      "2021-09-18 18:52:49,159 : - EPOCH 21 - PROGRESS: at 79.60% examples, 374489 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:49,347 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:49,371 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:49,377 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:49,378 : - EPOCH - 21 : training on 540242 raw words (486152 effective words) took 1.3s, 388296 effective words/s\n",
      "2021-09-18 18:52:50,417 : - EPOCH 22 - PROGRESS: at 68.53% examples, 323280 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:50,754 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:50,790 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:50,801 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:50,803 : - EPOCH - 22 : training on 540242 raw words (486135 effective words) took 1.4s, 343492 effective words/s\n",
      "2021-09-18 18:52:51,859 : - EPOCH 23 - PROGRESS: at 79.60% examples, 369661 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:52,062 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:52,064 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:52,080 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:52,082 : - EPOCH - 23 : training on 540242 raw words (486158 effective words) took 1.3s, 383082 effective words/s\n",
      "2021-09-18 18:52:53,126 : - EPOCH 24 - PROGRESS: at 81.44% examples, 382641 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:53,281 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:53,314 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:53,336 : - worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:52:53,338 : - EPOCH - 24 : training on 540242 raw words (486138 effective words) took 1.2s, 390275 effective words/s\n",
      "2021-09-18 18:52:54,354 : - EPOCH 25 - PROGRESS: at 81.44% examples, 392915 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:54,543 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:54,557 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:54,560 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:54,563 : - EPOCH - 25 : training on 540242 raw words (486147 effective words) took 1.2s, 399723 effective words/s\n",
      "2021-09-18 18:52:55,581 : - EPOCH 26 - PROGRESS: at 77.75% examples, 374779 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:55,779 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:55,799 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:55,832 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:55,834 : - EPOCH - 26 : training on 540242 raw words (486104 effective words) took 1.3s, 385568 effective words/s\n",
      "2021-09-18 18:52:56,857 : - EPOCH 27 - PROGRESS: at 81.45% examples, 390239 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:57,009 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:57,053 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:57,054 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:57,055 : - EPOCH - 27 : training on 540242 raw words (486154 effective words) took 1.2s, 400973 effective words/s\n",
      "2021-09-18 18:52:58,067 : - EPOCH 28 - PROGRESS: at 79.60% examples, 386059 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:58,254 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:58,285 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:58,307 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:58,308 : - EPOCH - 28 : training on 540242 raw words (486080 effective words) took 1.2s, 391017 effective words/s\n",
      "2021-09-18 18:52:59,331 : - EPOCH 29 - PROGRESS: at 79.60% examples, 381704 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:52:59,525 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:52:59,543 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:52:59,552 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:52:59,553 : - EPOCH - 29 : training on 540242 raw words (486246 effective words) took 1.2s, 393537 effective words/s\n",
      "2021-09-18 18:53:00,566 : - EPOCH 30 - PROGRESS: at 79.60% examples, 384961 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-18 18:53:00,762 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-18 18:53:00,767 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-18 18:53:00,804 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-18 18:53:00,806 : - EPOCH - 30 : training on 540242 raw words (486051 effective words) took 1.2s, 390721 effective words/s\n",
      "2021-09-18 18:53:00,806 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14583945 effective words) took 38.4s, 380010 effective words/s', 'datetime': '2021-09-18T18:53:00.806952', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14583945, 16207260)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treinamento do modelo Skip-gram\n",
    "# Skip-Gram possui um resultado melhor com um window maior, por isso, alterado de 2 para 5\n",
    "\n",
    "w2v_modelo_sg = Word2Vec(sg = 1,\n",
    "                     window = 5,\n",
    "                     #size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)\n",
    "\n",
    "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
    "\n",
    "w2v_modelo_sg.train(lista_lista_tokens,\n",
    "                 total_examples=w2v_modelo_sg.corpus_count,\n",
    "                 epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96aba9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 0.6828131675720215),\n",
       " ('facebook', 0.656792402267456),\n",
       " ('app', 0.5954843163490295),\n",
       " ('chips', 0.5801985263824463),\n",
       " ('toshiba', 0.5645671486854553),\n",
       " ('amazon', 0.5596395134925842),\n",
       " ('yahoo', 0.5568916201591492),\n",
       " ('android', 0.5563364624977112),\n",
       " ('reguladores', 0.5473930239677429),\n",
       " ('waze', 0.5408293604850769)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"google\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5485e",
   "metadata": {},
   "source": [
    "# Funções para validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3dfbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 19:09:11,126 : - loading projection weights from modelos/modelo_cbow.txt\n",
      "2021-09-18 19:09:12,767 : - KeyedVectors lifecycle event {'msg': 'loaded (12924, 100) matrix of type float32 from modelos/modelo_cbow.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-09-18T19:09:12.767799', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'load_word2vec_format'}\n",
      "2021-09-18 19:09:12,769 : - loading projection weights from modelos/modelo_skipgram.txt\n",
      "2021-09-18 19:09:14,176 : - KeyedVectors lifecycle event {'msg': 'loaded (12924, 100) matrix of type float32 from modelos/modelo_skipgram.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-09-18T19:09:14.176913', 'gensim': '4.1.1', 'python': '3.7.12 (default, Sep  8 2021, 01:20:16) \\n[GCC 10.2.1 20210110]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-11.0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_modelo_cbow = KeyedVectors.load_word2vec_format(\"modelos/modelo_cbow.txt\")\n",
    "w2v_modelo_sg = KeyedVectors.load_word2vec_format(\"modelos/modelo_skipgram.txt\")\n",
    "artigo_treino = pd.read_csv(\"data/treino.csv\")\n",
    "artigo_teste = pd.read_csv(\"data/teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0caf4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rio', 'janeiro', 'cidade', 'maravilhosa']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\", disable=[\"parser\", \"ner\", \"tagger\", \"textcat\"])\n",
    "\n",
    "def tokenizador(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text.lower())\n",
    "    \n",
    "    return tokens_validos\n",
    "\n",
    "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
    "tokens = tokenizador(texto)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea51e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:  ['rio', 'janeiro', 'cidade', 'maravilhosa']\n",
      "w2v_modelo_cbow:  <gensim.models.keyedvectors.KeyedVectors object at 0x7f79bf8b7f50>\n"
     ]
    }
   ],
   "source": [
    "def combinacao_de_vetores_por_soma(palavras, modelo):\n",
    "\n",
    "    vetor_resultante = np.zeros((1,300))\n",
    "\n",
    "    for pn in palavras:\n",
    "        try:\n",
    "            vetor_resultante += modelo.get_vector(pn)\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "                \n",
    "\n",
    "    return vetor_resultante\n",
    "\n",
    "print(\"tokens: \", tokens)\n",
    "print(\"w2v_modelo_cbow: \", w2v_modelo_cbow)\n",
    "#vetor_texto = combinacao_de_vetores_por_soma(tokens, w2v_modelo_cbow)\n",
    "#print(vetor_texto.shape)\n",
    "#print(vetor_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5ca69ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'artigo_treino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/2877845315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatriz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmatriz_vetores_treino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatriz_vetores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martigo_treino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmatriz_vetores_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatriz_vetores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martigo_treino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatriz_vetores_treino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'artigo_treino' is not defined"
     ]
    }
   ],
   "source": [
    "def matriz_vetores(textos):\n",
    "    x = len(textos)\n",
    "    y = 300\n",
    "    matriz = np.zeros((x,y))\n",
    "    \n",
    "    for i in range(x):\n",
    "        palavras_numeros = tokenizador(textos.iloc[i])\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(palavras_numeros)\n",
    "        \n",
    "    return matriz\n",
    "\n",
    "matriz_vetores_treino = matriz_vetores(artigo_treino.title)\n",
    "matriz_vetores_teste = matriz_vetores(artigo_treino.title)\n",
    "print(matriz_vetores_treino)\n",
    "print(matriz_vetores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinacao_vetores_por_soma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98c91945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 18:41:28,433 : - storing 12924x100 projection weights into modelos/modelo_cbow.txt\n",
      "2021-09-15 18:41:29,769 : - storing 12924x100 projection weights into modelos/modelo_skipgram.txt\n"
     ]
    }
   ],
   "source": [
    "w2v_modelo.wv.save_word2vec_format(\"modelos/modelo_cbow.txt\", binary=False)\n",
    "w2v_modelo_sg.wv.save_word2vec_format(\"modelos/modelo_skipgram.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c0a6265",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/local/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/3235702663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlista_alfanumerico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtokenizador\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Texto Exemplo, 1234.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_33/3235702663.py\u001b[0m in \u001b[0;36mtokenizador\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlista_alfanumerico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken_valido\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_valido\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mponctuation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlista_alfanumerico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_valido\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     return [\n\u001b[1;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/local/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "def tokenizador(texto):\n",
    "    texto = texto.lower()\n",
    "    lista_alfanumerico = []\n",
    "    \n",
    "    for token_valido in nltk.word_tokenize(texto):\n",
    "        if token_valido in string.ponctuation: continue\n",
    "        lista_alfanumerico.append(token_valido)\n",
    "            \n",
    "    return lista_alfanumerico\n",
    "\n",
    "tokenizador(\"Texto Exemplo, 1234.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a9025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
